{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run first, standard stuff\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "Load mnist digits data set. Estimate base line prediction accuracy with SDGClassifier (20 iteractions), RandomForest(max_depth=3) and RandomForest(max_depth=15). Train model on training data and predict accuracy using testing data. Record the amount of time needed to estimate each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "from six.moves import urllib\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "Apply PCA to extract principle components responsible for 90% of variance. Apply the algorithms above to the components. Report new accuracy score. Make sure to apply PCA to the data before the split into training and testing. Record time of the PCA procedure and record separately time and accuracy of each estimation and report changes relative to Problem 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "\n",
    "Load the same data. Extract 1000 observations, use the code below. Try five different PCA alogrithms that would extract 100 principle components. Use the following PCA algorithms: PCA,  Kernel PCA(Linear), Kernel PCA(Sigmoid(gamma=0.001), LLE (10 neighbors), Isomap. Then estimate logistic regression on the training data and test the accuracy using testing data. \n",
    "* What are the accuracy score on testing data you find with each PCA algorithm? \n",
    "* Which PCA algorithm has the highest prediction accuracy?\n",
    "* What is the accuracy of the logistic regression applied to the 1000 obs without applying PCA? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample 1000 obs, otherwise it will get really slow.\n",
    "np.random.seed(42)\n",
    "smp = np.random.randint(50000, size=1000)\n",
    "X_s = mnist[\"data\"][smp,:]\n",
    "y_s = mnist[\"target\"][smp]\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_s, y_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
